



漏洞描述： 

redis 默认不需要密码即可访问，黑客直接访问即可获取数据库中所有信息，造成严重的信息泄露。

 

修复方案： 

1、绑定需要访问数据库的IP

修改 redis.conf 中的 “bind 127.0.0.1” ，改成需要访问此数据库的IP地址。 

2、设置访问密码

在 redis.conf 中找到“requirepass”字段，在后面填上你需要的密码。 

 

注：上述两种方法修改后，需要重启redis才能生效。


Redis 数据备份与恢复
Redis SAVE 命令用于创建当前数据库的备份。
语法
redis Save 命令基本语法如下：
redis 127.0.0.1:6379> SAVE
实例
redis 127.0.0.1:6379> SAVE
OK
该命令将在 redis 安装目录中创建dump.rdb文件。
恢复数据
如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令，




extension=php_igbinary.dll
extension=php_redis.dll           windows上要装这两个
http://pecl.php.net/package/redis   官方网站上有安装包 



redis 是什么 :

redis 是开源 ,BSD 许可 , 高级的 key-value 存储系统 . 


可以用来存储字符串 , 哈希结构 , 链表 , 集合 , 因此 , 常用来提供数据结构服务 .

 

redis 和 memcached 相比 , 的独特之处 :

1: redis 可以用来做存储 (storge),

  而 memccached 是用来做缓存 (cache) 这个特点主要因为其有 ” 持久化 ” 的功能 .

2:  存储的数据有 ” 结构 ” , 对于 memcached 来说 , 存储的数据 , 只有 1 种类型 -- ” 字符串 ” ,

  而 redis 则可以存储字符串 , 链表 , 哈希结构 , 集合 , 有序集合 .




Redis 下载安装

 

1: 官方站点 : redis.io  下载最新版或者最新 stable 版

2: 解压源码并进入目录

3:  不用 configure

4:  直接 make 

( 如果是 32 位机器  make 32bit)

 

注 : 易碰到的问题 , 时间错误 .

原因 :  源码是官方 configure 过的 , 但官方 configure 时 , 生成的文件有时间戳信息 ,

Make 只能发生在 configure 之后 ,

如果你的虚拟机的时间不对 , 比如说是 2012 年

解决 : date -s  ‘ yyyy-mm-dd hh:mm:ss ’    重写时间

    再  clock -w   写入 cmos

 

 

5:  可选步骤 : make test   测试编译情况

( 可能出现 : need tcl  >8.4 这种情况 , yum install tcl)
make tests   若出要安装ctl的错   $ sudo yum install tcl   然后   ./runtest

   打开文件redis.conf,修改 ”daemonize no“ 为 “daemonize yes”，  

6:  安装到指定的目录 , 比如  /usr/local/redis

make  PREFIX=/usr/local/redis install

注 : PREFIX 要大写

 

7: make install 之后 , 得到如下几个文件

redis-benchmark   性能测试工具

redis-check-aof   日志文件检测工 ( 比如断电造成日志损坏 , 可以检测并修复 )

redis-check-dump   快照文件检测工具 , 效果类上

redis-cli   客户端

redis-server  服务端

 

 

 

8:  复制配置文件

Cp /path/redis.conf /usr/local/redis

 

 

9:  启动与连接

/path/to/redis/bin/redis-server  ./path/to/conf-file

例 : [root@localhost redis]# ./bin/redis-server ./redis.conf 

 

连接 :  用 redis-cli

#/path/to/redis/bin/redis-cli [-h localhost -p 6379 ]

 

 

10:  让 redis 以后台进程的形式运行

编辑 conf 配置文件 , 修改如下内容 ;

daemonize yes


Redis对于key的操作命令

 

del key1 key2 ... Keyn

作用 :  删除 1 个或多个键

返回值 :  不存在的 key 忽略掉 , 返回真正删除的 key 的数量

 

rename key newkey

作用 :  给 key 赋一个新的 key 名

注 : 如果 newkey 已存在 , 则 newkey 的原值被覆盖

 

renamenx key newkey  

作用 :  把 key 改名为 newkey

返回 :  发生修改返回 1, 未发生修改返回 0

注 : nx--> not exists,  即 , newkey 不存在时 , 作改名动作

 

move key db

===================数据库的概念====================

redis 127.0.0.1:6379[1]>  select 2   选库

OK

redis 127.0.0.1:6379[2]> keys *

(empty list or set)

redis 127.0.0.1:6379[2]> select 0

OK

redis 127.0.0.1:6379> keys *

1) "name"

2) "cc"

3) "a"

4) "b"

redis 127.0.0.1:6379> move cc 2

(integer) 1

redis 127.0.0.1:6379> select 2

OK

redis 127.0.0.1:6379[2]> keys *

1) "cc"

redis 127.0.0.1:6379[2]> get cc

"3"

( 注意 :  一个 redis 进程 , 打开了不止一个数据库 ,  默认打开 16 个数据库 , 从 0 到 15 编号 , 如果想打开更多数据库 , 可以从配置文件修改 )



keys pattern 查询相应的key

在 redis 里 , 允许模糊查询 key

有 3 个通配符  *, ? ,[  ]

*:  通配任意多个字符

?:  通配单个字符

[ ]:  通配括号内的某 1 个字符

redis 127.0.0.1:6379> flushdb

OK

redis 127.0.0.1:6379> keys *

(empty list or set)

redis 127.0.0.1:6379> mset one 1 two 2 three 3 four 4

OK

redis 127.0.0.1:6379> keys o*

1) "one"

redis 127.0.0.1:6379> key *o

(error) ERR unknown command 'key'

redis 127.0.0.1:6379> keys *o

1) "two"

redis 127.0.0.1:6379> keys ???

1) "one"

2) "two"

redis 127.0.0.1:6379> keys on?

1) "one"

redis 127.0.0.1:6379> set ons yes

OK

redis 127.0.0.1:6379> keys on[eaw]

1)  "one"

 

 

randomkey 返回随机key

exists key

判断 key 是否存在 , 返回 1/0

type key

返回 key 存储的值的类型

有 string,link,set,order set, hash  

ttl key 

作用 :  查询 key 的生命周期

返回 :  秒数

注 : 对于不存在的 key 或已过期的 key/ 不过期的 key, 都返回 -1

Redis2.8 中 , 对于不存在的 key, 返回 -2

expire key 整型值

作用 :  设置 key 的生命周期 , 以秒为单位

同理 : 

pexpire key  毫秒数 ,  设置生命周期

pttl  key,  以毫秒返回生命周期

 

persist key

作用 :  把指定 key 置为永久有效

Flushdb   清空 key


Redis字符串类型的操作

set key value [ex 秒数] / [px 毫秒数]  [nx] /[xx]

如 : set a 1 ex 10 , 10 秒有效

Set a 1 px 9000  , 9 秒有效

注 :  如果 ex,px 同时写 , 以后面的有效期为准

如  set a 1 ex 100 px 9000,  实际有效期是 9000 毫秒

nx :  表示 key 不存在时 , 执行操作

xx :  表示 key 存在时 , 执行操作

 

mset  multi set , 一次性设置多个键值

例 : mset key1 v1 key2 v2 ....

get key 

作用 : 获取 key 的值

mget key1 key2 ..keyn

作用 : 获取多个 key 的值

setrange key offset value

作用 : 把字符串的 offset 偏移字节 , 改成 value

redis 127.0.0.1:6379> set greet hello

OK

redis 127.0.0.1:6379> setrange greet 2 x

(integer) 5

redis 127.0.0.1:6379> get greet

"hexlo"

 

注意 :  如果偏移量 > 字符长度 ,  该字符自动补 0x00

 

redis 127.0.0.1:6379> setrange greet 6 !

(integer) 7

redis 127.0.0.1:6379> get greet

"heyyo\x00!"

 

append key value

作用 :  把 value 追加到 key 的原值上

getrange key start stop

作用 :  是获取字符串中  [start, stop] 范围的值

注意 :  对于字符串的下标 , 左数从 0 开始 , 右数从 -1 开始

redis 127.0.0.1:6379> set title 'chinese'

OK

redis 127.0.0.1:6379> getrange title 0 3

"chin"

redis 127.0.0.1:6379> getrange title 1 -2

"hines"

 

注意 : 

1: start>=length,  则返回空字符串

2: stop>=length, 则截取至字符结尾

3:  如果 start  所处位置在 stop 右边 ,  返回空字符串

getset key newvalue

作用 :  获取并返回旧值 , 设置新值

redis 127.0.0.1:6379> set cnt 0

OK

redis 127.0.0.1:6379> getset cnt 1

"0"

redis 127.0.0.1:6379> getset cnt 2

"1"

 

incr key

作用 :  指定的 key 的值加 1, 并返回加 1 后的值

注意 :

1: 不存在的 key 当成 0, 再 incr 操作

2:  范围为 64 有符号


incrby key number

redis 127.0.0.1:6379> incrby age  90

(integer) 92

incrbyfloat key floatnumber

redis 127.0.0.1:6379> incrbyfloat age 3.5

"95.5"

decr key

redis 127.0.0.1:6379> set age 20

OK

redis 127.0.0.1:6379> decr age

(integer) 19

 

decrby key number

redis 127.0.0.1:6379> decrby age 3

(integer) 16

getbit key offset

作用 : 获取值的二进制表示 , 对应位上的值 ( 从左 , 从 0 编号 )

redis 127.0.0.1:6379> set char A

OK

redis 127.0.0.1:6379> getbit char 1

(integer) 1

redis 127.0.0.1:6379> getbit char 2

(integer) 0

redis 127.0.0.1:6379> getbit char 7

(integer) 1

setbit  key offset value

设置 offset 对应二进制位上的值

返回 :  该位上的旧值

 

注意 : 

1: 如果 offset 过大 , 则会在中间填充 0,

2: offset 最大大到多少

3:offset 最大 2^32-1, 可推出最大的的字符串为 512M

 

bitop operation destkey key1 [key2 ...]

 

对 key1,key2..keyN 作 operation, 并将结果保存到  destkey  上。

operation  可以是  AND  、  OR  、  NOT  、  XOR

 

redis 127.0.0.1:6379> setbit lower 7 0

(integer) 0

redis 127.0.0.1:6379> setbit lower 2 1

(integer) 0

redis 127.0.0.1:6379> get lower

" "

redis 127.0.0.1:6379> set char Q

OK

redis 127.0.0.1:6379> get char

"Q"

redis 127.0.0.1:6379> bitop or char char lower

(integer) 1

redis 127.0.0.1:6379> get char

"q"

注意 :  对于 NOT 操作 , key 不能多个


link 链表结构

lpush key value 

作用 :  把值插入到链接头部

 

rpop key

作用 :  返回并删除链表尾元素

rpush,lpop:  不解释

lrange key start  stop

作用 :  返回链表中 [start ,stop] 中的元素

规律 :  左数从 0 开始 , 右数从 -1 开始        lrange key 0  -1

lrem key count value

作用 :  从 key 链表中删除  value 值

注 :  删除 count 的绝对值个 value 后结束

Count>0  从表头删除

Count<0  从表尾删除

 

ltrim key start stop

作用 :  剪切 key 对应的链接 , 切 [start,stop] 一段 , 并把该段重新赋给 key

lindex key index

作用 :  返回 index 索引上的值 ,

如   lindex key 2

llen key

作用 : 计算链接表的元素个数

redis 127.0.0.1:6379> llen task

(integer) 3

linsert  key after|before search value

作用 :  在 key 链表中寻找 ’ search ’ , 并在 search 值之前 | 之后 ,. 插入 value

注 :  一旦找到一个 search 后 , 命令就结束了 , 因此 不会插入多 个 value

rpoplpush source dest

作用 :  把 source 的尾部拿出 , 放在 dest 的头部 ,

并返回 该单元值

场景 : task + bak  双链表完成 安全队列

Task 列表                              bak 列表

  

  

  


  

  

  


操作原子性

业务逻辑 :

1:Rpoplpush task bak

2: 接收返回值 , 并做业务处理

3: 如果成功 ,rpop bak  清除任务 .  如不成功 , 下次从 bak 表里取任务

brpop ,blpop  key timeout

作用 : 等待弹出 key 的尾 / 头元素 , 

Timeout 为等待超时时间

如果 timeout 为 0, 则一直等待

场景 :  长轮询 Ajax, 在线聊天时 , 能够用到


Setbit  的实际应用

场景 : 1 亿个用户 ,  每个用户 登陆 / 做任意操作   , 记为 今天活跃 , 否则记为不活跃

每周评出 :  有奖活跃用户 :  连续 7 天活动       每月评 , 等等 ...

思路 : 

Userid       dt            active

1        2013-07-27           1

1       2013-0726             1

 

如果是放在表中 , 1: 表急剧增大 ,2: 要用 group ,sum 运算 , 计算较慢

用 :  位图法  bit-map

Log0721:   ‘ 011001...............0 ’

......

log0726 :    ‘ 011001...............0 ’

Log0727 :   ‘ 0110000.............1 ’

1:  记录用户登陆 :

每天按日期生成一个位图 ,  用户登陆后 , 把 user_id 位上的 bit 值置为 1

2:  把 1 周的位图   and  计算 , 

位上为 1 的 , 即是连续登陆的用户




redis 127.0.0.1:6379> setbit mon 100000000 0

(integer) 0

redis 127.0.0.1:6379> setbit mon 3 1

(integer) 0

redis 127.0.0.1:6379> setbit mon 5 1

(integer) 0

redis 127.0.0.1:6379> setbit mon 7 1

(integer) 0

redis 127.0.0.1:6379> setbit  thur  100000000 0

(integer) 0

redis 127.0.0.1:6379> setbit  thur  3 1

(integer) 0

redis 127.0.0.1:6379> setbit  thur  5 1

(integer) 0

redis 127.0.0.1:6379> setbit  thur  8 1

(integer) 0

redis 127.0.0.1:6379> setbit wen 100000000 0

(integer) 0

redis 127.0.0.1:6379> setbit wen 3 1

(integer) 0

redis 127.0.0.1:6379> setbit wen 4 1

(integer) 0

redis 127.0.0.1:6379> setbit wen 6 1

(integer) 0

redis 127.0.0.1:6379> bitop and  res mon feb wen

(integer) 12500001

 

如上例 , 优点 :

1:  节约空间 , 1 亿人每天的登陆情况 , 用 1 亿 bit, 约 1200WByte, 约 10M  的字符就能表示

2:  计算方便




集合 set 相关命令




集合的性质 :  唯一性 , 无序性 , 确定性

注 :  在 string 和 link 的命令中 , 可以通过 range  来访问 string 中的某几个字符或某几个元素

但 , 因为集合的无序性 , 无法通过下标或范围来访问部分元素 .

因此想看元素 , 要么随机先一个 , 要么全选  

sadd key  value1 value2

作用 :  往集合 key 中增加元素

srem value1 value2

作用 :  删除集合中集为  value1 value2 的元素

返回值 :  忽略不存在的元素后 , 真正删除掉的元素的个数

spop key

作用 :  返回并删除集合中 key 中 1 个随机元素

随机 -- 体现了无序性

srandmember key

作用 :  返回集合 key 中 , 随机的 1 个元素 .

sismember key  value

作用 :  判断 value 是否在 key 集合中

是返回 1, 否返回 0

smembers key

作用 :  返回集中中所有的元素

scard key

作用 :  返回集合中元素的个数

smove source dest value

作用 : 把 source 中的 value 删除 , 并添加到 dest 集合中

sinter   key1 key2 key3

作用 :  求出 key1 key2 key3  三个集合中的交集 , 并返回

redis 127.0.0.1:6379> sadd s1 0 2 4 6

(integer) 4

redis 127.0.0.1:6379> sadd s2 1 2 3 4

(integer) 4

redis 127.0.0.1:6379> sadd s3 4 8 9 12

(integer) 4

redis 127.0.0.1:6379> sinter s1 s2 s3

1) "4"

redis 127.0.0.1:6379> sinter s3 s1 s2

1)  "4"

 

sinterstore dest key1 key2 key3

作用 :  求出 key1 key2 key3  三个集合中的交集 , 并赋给 dest

suion key1 key2.. Keyn

作用 :  求出 key1 key2 keyn 的并集 , 并返回

sdiff key1 key2 key3 

作用 :  求出 key1 与 key2 key3 的 差集

即 key1-key2-key3 

order set 有序集合

zadd key  score1  value1  score2  value2 ..

添加元素    有 score 才能排序呢,才是有序的

redis 127.0.0.1:6379> zadd stu 18 lily 19 hmm 20 lilei 21 lilei

(integer) 3

zrem key value1 value2 ..

作用 :  删除集合中的元素

zremrangeby score  key min max

作用 :  按照 socre 来删除元素 , 删除 score 在 [min,max] 之间的

redis 127.0.0.1:6379> zremrangebyscore stu 4 10

(integer) 2

redis 127.0.0.1:6379> zrange stu 0 -1

1) "f"

zremrangebyrank key start end

作用 :  按排名删除元素 , 删除名次在 [start,end] 之间的

redis 127.0.0.1:6379> zremrangebyrank stu 0 1

(integer) 2

redis 127.0.0.1:6379> zrange stu 0 -1

1) "c"

2) "e"

3) "f"

4) "g"

 

zrank key member

查询 member 的排名 ( 升续  0 名开始 )       查询排在第几位

zrevrank key memeber

查询  member 的排名 ( 降续  0 名开始 )

zrange key start stop [WITHSCORES]

把集合排序后 , 返回名次 [ start ,s top ] 的元素

默认是升续排列 

Withscores  是把 score 也打印出来

 

zrevrange key start stop    当然按score排序了

作用 : 把集合降序排列 , 取名字 [start,stop] 之间的元素

 

zrangebyscore  key min max [withscores] limit offset N 当然按score排序

作用 :  集合 ( 升续 ) 排序后 , 取 score 在 [min,max] 内的元素 ,

并跳过  offset 个 ,  取出 N 个

redis 127.0.0.1:6379> zadd stu 1 a 3 b 4 c 9 e 12 f 15 g

(integer) 6

redis 127.0.0.1:6379> zrangebyscore stu 3 12 limit 1 2 withscores

1) "c"

2) "4"

3) "e"

4) "9"  

zcard key

返回元素个数

zcount key min max

返回 [min,max]  区间内元素的数量

zinterstore destination numkeys key1 [key2 ...]       [WEIGHTS weight [weight ...]]        [AGGREGATE SUM|MIN|MAX]

  numkeys 是取几个

求 key1,key2 的交集 ,key1,key2 的权重分别是  weight1,weight2

聚合方法用 : sum |min|max

聚合的结果 , 保存在 dest 集合内

 

注意 : weights ,aggregate 如何理解 ?

答 :  如果有交集 ,  交集元素又有 socre,score 怎么处理 ?

 Aggregate sum->score 相加    , min  求最小 score, max  最大 score

另 :  可以通过 weigth 设置不同 key 的权重 ,  交集时 ,socre * weights

 

详见下例

redis 127.0.0.1:6379> zadd z1 2 a 3 b 4 c

(integer) 3

redis 127.0.0.1:6379> zadd z2 2.5 a 1 b 8 d

(integer) 3

redis 127.0.0.1:6379> zinterstore tmp 2 z1 z2

(integer) 2

redis 127.0.0.1:6379> zrange tmp 0 -1

1) "b"

2) "a"

redis 127.0.0.1:6379> zrange tmp 0 -1 withscores

1) "b"

2) "4"

3) "a"

4) "4.5"

redis 127.0.0.1:6379> zinterstore tmp 2 z1 z2 aggregate sum

(integer) 2

redis 127.0.0.1:6379> zrange tmp 0 -1 withscores

1) "b"

2) "4"

3) "a"

4) "4.5"

redis 127.0.0.1:6379> zinterstore tmp 2 z1 z2 aggregate min

(integer) 2

redis 127.0.0.1:6379> zrange tmp 0 -1 withscores

1) "b"

2) "1"

3) "a"

4) "2"

redis 127.0.0.1:6379> zinterstore tmp 2 z1 z2 weights 1 2

(integer) 2

redis 127.0.0.1:6379> zrange tmp 0 -1 withscores

1) "b"

2) "5"

3) "a"

4) "7"





Hash 哈希数据类型相关命令

 

hset key field value

作用 :  把 key 中  filed 域的值设为 value

注 : 如果没有 field 域 , 直接添加 , 如果有 , 则覆盖原 field 域的值

hmset key field1 value1 [field2 value2 field3 value3 ......fieldn valuen]

作用 :  设置 field1->N  个域 ,  对应的值是 value1->N

( 对应 PHP 理解为   $key = array(file1=>value1, field2=>value2 ....fieldN=>valueN))

hget key field

作用 :  返回 key 中 field 域的值

hmget key field1 field2 fieldN

作用 :  返回 key 中 field1 field2 fieldN 域的值

hgetall key

作用 : 返回 key 中 , 所有域与其值

hdel key field

作用 :  删除 key 中  field 域

hlen key

作用 :  返回 key 中元素的数量

hexists key field

作用 :  判断 key 中有没有 field 域

hinrby  key field value

作用 :  是把 key 中的 field 域的值 增长整型值 value

hinrby float  key field value

作用 :  是把 key 中的 field 域的值 增长浮点值 value  

hkeys key

作用 :  返回 key 中所有的 field

kvals key

作用 :  返回 key 中所有的 value

Redis 中的事务  

Redis 支持简单的事务

Redis 与  mysql 事务的对比

  

 Mysql

 Redis


 开启

 start transaction

 muitl


 语句

 普通 sql

 普通命令


 失败

 rollback  回滚

 discard  取消


 成功

 commit

 exec


 

注 : rollback 与 discard  的区别

如果已经成功执行了 2 条语句 ,  第 3 条语句出错 .

Rollback 后 , 前 2 条的语句影响消失 .

Discard 只是结束本次事务 , 前 2 条语句造成的影响仍然还在

 

注 :

在 mutil 后面的语句中 ,  语句出错可能有 2 种情况

1:  语法就有问题 , 

这种 ,exec 时 , 报错 ,  所有语句得不到执行

 

2:  语法本身没错 , 但适用对象有问题 .  比如  zadd  操作 list 对象

Exec 之后 , 会执行正确的语句 , 并跳过有不适当的语句 .

( 如果 zadd 操作 list 这种事怎么避免 ?  这一点 , 由程序员负责 )

 

思考 : 

我正在买票

Ticket -1 , money -100

而票只有 1 张 ,  如果在我 multi 之后 , 和 exec 之前 ,  票被别人买了 --- 即 ticket 变成 0 了 .

我该如何观察这种情景 , 并不再提交

悲观的想法 :  

世界充满危险 , 肯定有人和我抢 ,  给  ticket 上锁 ,  只有我能操作 . [ 悲观锁 ]

乐观的想法 :

没有那么人和我抢 , 因此 , 我只需要注意 ,

-- 有没有人更改 ticket 的值就可以了  [ 乐观锁 ]

Redis 的事务中 , 启用的是乐观锁 , 只负责监测 key 没有被改动 . 要是改了就不执行了

 

具体的命令 ----  watch 命令

例 : 

redis 127.0.0.1:6379>  watch  ticket

OK

redis 127.0.0.1:6379> multi

OK

redis 127.0.0.1:6379> decr ticket

QUEUED

redis 127.0.0.1:6379> decrby money 100

QUEUED

redis 127.0.0.1:6379> exec

(nil)     //  返回 nil, 说明监视的 ticket 已经改变了 , 事务就取消了 .

redis 127.0.0.1:6379> get ticket

"0"

redis 127.0.0.1:6379> get money

"200"

 

watch key1 key2  ... keyN

作用 : 监听 key1 key2..keyN 有没有变化 , 如果有变 ,  则事务取消

unwatch 

作用 :  取消所有 watch 监听

消息订阅

订阅端 : Subscribe  频道名称

发布端 : publish  频道名称 发布内容

客户端例子 :

redis 127.0.0.1:6379> subscribe news

redis 127.0.0.1:6379> p subscribe news *    通配的订阅




Reading messages... (press Ctrl-C to quit)

1) "subscribe"

2) "news"

3) (integer) 1

1) "message"

2) "news"

3) "good good study"

1) "message"

2) "news"

3) "day day up"

 

服务端例子 :

redis 127.0.0.1:6379> publish news 'good good study'

(integer) 1

redis 127.0.0.1:6379> publish news 'day day up'

(integer) 1

 





Redis 持久化配置

 

Redis 的持久化有 2 种方式     1 快照   2 是日志

 

Rdb 快照的配置选项

save 900 1       // 900 内 , 有 1 条写入 , 则产生快照 

save 300 10 00   //  如果 300 秒内有 1000 次写入 , 则产生快照

save 60 10000   //  如果 60 秒内有 10000 次写入 , 则产生快照

( 这 3 个选项都屏蔽 , 则 rdb 禁用 )

 

stop-writes-on-bgsave-error yes   //  后台备份进程出错时 , 主进程停不停止写入 ?

rdbcompression yes     //  导出的 rdb 文件是否压缩

Rdbchecksum   yes //   导入 rbd 恢复时数据时 , 要不要检验 rdb 的完整性

dbfilename dump.rdb   // 导出来的 rdb 文件名

dir ./   //rdb 的放置路径

Aof  的配置

appendonly no  #  是否打开  aof 日志功能

appendfsync always    #  每 1 个命令 , 都立即同步到 aof.  安全 , 速度慢

appendfsync everysec  #  折衷方案 , 每秒写 1 次

appendfsync no       #  写入工作交给操作系统 , 由操作系统判断缓冲区大小 , 统一写入到 aof.  同步频率低 , 速度快 ,

 

 

no-appendfsync-on-rewrite   yes: #  正在导出 rdb 快照的过程中 , 要不要停止同步 aof

auto-aof-rewrite-percentage 100  #aof 文件大小比起上次重写时的大小 , 增长率 100% 时 , 重写

auto-aof-rewrite-min-size 64mb  #aof 文件 , 至少超过 64M 时 , 重写





注 :  在 dump rdb 过程中 ,aof 如果停止同步 , 会不会丢失 ?

答 :  不会 , 所有的操作缓存在内存的队列里 , dump 完成后 , 统一操作 .

 

注 : aof 重写是指什么 ?

答 : aof 重写是指把内存中的数据 , 逆化成命令 , 写入到 .aof 日志里 .

以解决  aof 日志过大的问题 .

问 :  如果 rdb 文件 , 和 aof 文件都存在 , 优先用谁来恢复数据 ?

答 : aof

问 : 2 种是否可以同时用 ?

答 :  可以 , 而且推荐这么做

问 :  恢复时 rdb 和 aof 哪个恢复的快

答 : rdb 快 , 因为其是数据的内存映射 , 直接载入到内存 , 而 aof 是命令 , 需要逐条执行






redis  服务器端命令

redis 127.0.0.1:6380> time   , 显示服务器时间  ,  时间戳 ( 秒 ),  微秒数

1) "1375270361"

2) "504511"

 

redis 127.0.0.1:6380> dbsize   //  当前数据库的 key 的数量

(integer) 2

redis 127.0.0.1:6380> select 2

OK

redis 127.0.0.1:6380[2]> dbsize

(integer) 0

redis 127.0.0.1:6380[2]> 

 

 

BGREWRITEAOF  后台进程重写 AOF

BGSAVE        后台保存 rdb 快照

SAVE          保存 rdb 快照

LASTSAVE      上次保存时间

 

Slaveof master-Host port  ,  把当前实例设为 master 的 slave

 

Flushall   清空所有库所有键 

Flushdb   清空当前库所有键

Showdown [save/nosave]

 

注 :  如果不小心运行了 flushall,  立即  shutdown nosave , 关闭服务器

然后 手工编辑 aof 文件 ,  去掉文件中的  “ flushall  ” 相关行 ,  然后开启服务器 , 就可以导入回原来数据 .

 

如果 ,flushall 之后 , 系统恰好 bgrewriteaof 了 , 那么 aof 就清空了 , 数据丢失 .

 

Slowlog  显示慢查询

注 : 多慢才叫慢 ? 

答 :  由 slowlog-log-slower-than 10000  , 来指定 ,( 单位是微秒 )

 

服务器储存多少条慢查询的记录 ?

答 :  由  slowlog-max-len 128  , 来做限制

 

Info [Replication/CPU/Memory..] 

查看 redis 服务器的信息

 

Config get  配置项  

Config set  配置项 值  ( 特殊的选项 , 不允许用此命令设置 , 如 slave-of,  需要用单独的 slaveof 命令来设置 )


Redis 运维时需要注意的参数

1:  内存

# Memory

used_memory:859192  数据结构的空间

used_memory_rss:7634944  实占空间

mem_fragmentation_ratio:8.89  前 2 者的比例 ,1.N 为佳 , 如果此值过大 , 说明 redis 的内存的碎片化严重 , 可以导出再导入一次 .

2:  主从复制

# Replication

role:slave

master_host:192.168.1.128

master_port:6379

master_link_status:up

 

3: 持久化

# Persistence

rdb_changes_since_last_save:0

rdb_last_save_time:1375224063

 

4: fork 耗时

#Status

latest_fork_usec:936   上次 导出 rdb 快照 , 持久化花费微秒

注意 :  如果某实例有 10G 内容 , 导出需要 2 分钟 ,

每分钟写入 10000 次 , 导致不断的 rdb 导出 , 磁盘始处于高 IO 状态 .

 

 

5:  慢日志

config get/set slowlog-log-slower-than

CONFIG get/SET slowlog-max-len 

slowlog get  N  获取慢日志


运行时更改 master-slave

修改一台 slave( 设为 A) 为 new master 

1)  命令该服务不做其他 redis 服务的 slave 

   命令 : slaveof no one 

2)  修改其 readonly 为 yes

 

其他的 slave 再指向 new master A

1)  命令该服务为 new master A 的 slave

   命令格式  slaveof IP port
监控工具  sentinel

 

 

Sentinel 不断与 master 通信 , 获取 master 的 slave 信息 .

监听 master 与 slave 的状态

如果某 slave 失效 , 直接通知 master 去除该 slave.

 

如果 master 失效 ,, 是按照 slave 优先级 ( 可配置 ),  选取 1 个 slave 做  new master

, 把其他 slave--> new master

 

疑问 : sentinel 与 master 通信 , 如果某次因为 master IO 操作频繁 , 导致超时 ,

此时 , 认为 master 失效 , 很武断 .

解决 : sentnel 允许多个实例看守 1 个 master,  当 N 台 (N 可设置 )sentinel 都认为 master 失效 , 才正式失效 .

 

Sentinel 选项配置

port 26379  #  端口

sentinel monitor  mymaster  127.0.0.1 6379   2   ,

给主机起的名字 ( 不重即可 ), 

当 2 个 sentinel 实例都认为 master 失效时 , 正式失效

 

sentinel down-after-milliseconds mymaster 30000   多少毫秒后连接不到 master 认为断开

sentinel can-failover mymaster yes  # 是否允许 sentinel 修改 slave->master.  如为 no, 则只能监控 , 无权修改 ./

sentinel parallel-syncs mymaster 1  ,  一次性修改几个 slave 指向新的 new master.

sentinel client-reconfig-script mymaster /var/redis/reconfig.sh  ,#  在重新配置 new master,new slave 过程 , 可以触发的脚本
redis 与关系型数据库的适合场景

 

书签系统


create table book (
 
bookid int,
 
title char(20)
 
)engine myisam charset utf8;
 
 
 
insert into book values
 
(5 , 'PHP圣经'),
 
(6 , 'ruby实战'),
 
(7 , 'mysql运维')
 
(8, 'ruby服务端编程');
 
 
 
 
 
create table tags (
 
tid int,
 
bookid int,
 
content char(20)
 
)engine myisam charset utf8;
 
 
 
insert into tags values
 
(10 , 5 , 'PHP'),
 
(11 , 5 , 'WEB'),
 
(12 , 6 , 'WEB'),
 
(13 , 6 , 'ruby'),
 
(14 , 7 , 'database'),
 
(15 , 8 , 'ruby'),
 
(16 , 8 , 'server');
 
 
 
# 既有web标签,又有PHP,同时还标签的书,要用连接查询
 
 
 
select * from tags inner join tags as t on tags.bookid=t.bookid
 
where tags.content='PHP' and t.content='WEB';
 
 
 
 
 
 
换成key-value存储
 
用kv 来存储
 
set book:5:title 'PHP圣经'
 
set book:6:title 'ruby实战'
 
set book:7:title 'mysql运难'
 
set book:8:title ‘ruby server’
 
 
 
sadd tag:PHP 5
 
sadd tag:WEB 5 6
 
sadd tag:database 7
 
sadd tag:ruby 6 8
 
sadd tag:SERVER 8
 
 
 
查: 既有PHP,又有WEB的书
 
Sinter tag:PHP tag:WEB  #查集合的交集
 
 
 
查: 有PHP或有WEB标签的书
 
Sunin tag:PHP tag:WEB
 
 
 
查:含有ruby,不含WEB标签的书
 
Sdiff tag:ruby tag:WEB #求差集
 
 
 
 



 

 


Redis key 设计技巧

1:  把表名转换为 key 前缀 如 , tag:

2:  第 2 段放置用于区分区 key 的字段 -- 对应 mysql 中的主键的列名 , 如 userid

3:  第 3 段放置主键值 , 如 2,3,4...., a , b ,c

4:  第 4 段 , 写要存储的列名

 用户表  user  ,  转换为 key-value 存储


 userid

 username

 passworde

 email


 9

 Lisi

 1111111

 lisi@163.com


 

set  user:userid:9:username lisi

set  user:userid:9:password 111111

set  user:userid:9:email   lisi@163.com  

keys user:userid:9*

 

2  注意 :

在关系型数据中 , 除主键外 , 还有可能其他列也步骤查询 ,

如上表中 , username  也是极频繁查询的 , 往往这种列也是加了索引的 .

 

转换到 k-v 数据中 , 则也要相应的生成一条按照该列为主的 key-value

Set  user:username:lisi:uid  9  

 

这样 , 我们可以根据 username:lisi:uid , 查出 userid=9, 

再查 user:9:password/email ...

 

完成了根据用户名来查询用户信息
php-redis 扩展编译

 

1:  到 pecl.php.net   搜索 redis

2:  下载 stable 版 ( 稳定版 ) 扩展

3:  解压 ,

4:  执行 /php/path/bin/phpize ( 作用是检测 PHP 的内核版本 , 并为扩展生成相应的编译配置 )

5: configure --with-php-config=/php/path/bin/php-config

6: make && make install

 

引入编译出的 redis.so 插件

1:  编辑 php.ini

2:  添加

 

 

redis 插件的使用

// get instance

$redis = new Redis();

 

// connect to redis server

$redis->open('localhost',6380);

$redis->set('user:userid:9:username','wangwu');

var_dump($redis->get('user:userid:9:username'));





微博项目的 key 设计

全局相关的 key:

 表名

 global


 列名

 操作

 备注


 Global:userid

 incr

 产生全局的 userid


 Global:postid

 Incr

 产生全局的 postid


 

 

用户相关的 key( 表 )

 表名

 user


 Userid

 Username

 Password

 Authsecret


 3

 Test3

 1111111

 #U*Q(%_


 

在 redis 中 , 变成以下几个 key

 Key 前缀

 user


 User:Userid:*

 User:userid:*Username

 User:userid:*Password

 User:userid:*:Authsecret


 User:userid:3

 User:userid:3:Test3

 User:userid:3:1111111

 User:userid:3:#U*Q(%_


 

 

微博相关的表设计

 表名

 post

  

  

  


 Postid

 Userid

 Username

 Time 

 Content


 4

 2

 Lisi

 1370987654f

 测试内容


 

微博在 redis 中 , 与表设计对应的 key 设计

 Key 前缀

 post

  

  

  


 Post:Postid:*

 Post:postid:*Userid

 Post:postid:*:Username

 Post:postid:*:Time 

 Post:postid:*:Content


 4

 2

 Lisi

 1370987654f

 测试内容


 


关注表 : following

Following:$userid -->

 

 

粉丝表

Follower:$userid --->

 

 

 

推送表 :revicepost

 

 3

 4

 7

  

  

  


 

 

 

 

================= 拉模型 , 改进 =====================

 

拉取表

 

 3

 4

 7

  

  

  


 

 

 

问 :  上次我拉取了  A->5,67, 三条微博 ,  下次刷新 home.php,  从 >7 的微博开始拉取

解决 :  拉取时 , 设定一个 lastpull 时间点 ,  下次拉取时 , 取 >lastpull 的微博

 

问 :  有很多关注人 , 如何取 ?

解决 :  循环自己的关注列表 , 逐个取他们的新微博

 

问 :  取出来之后放在哪儿 ?

答 : pull:$userid 的链接里

 

问 :  如果个人中心 , 只有前 1000 条

答 : ltrim, 只取前 1000 条

 

 

问 :  如果我关注  A,B 两人 ,  从 2 人中 , 各取 3 条最新信息

, 这 3+3 条信息 ,  从时间上 , 是交错的 ,  如何按时间排序 ?

答 :  我们发布时 ,  是发布的 hash 结构 ,  不能按时间来排序 .

 

解决 :   同步时 , 取微博后 , 记录本次取的微博的最大 id,

下次同步时 , 只取比最大 id 更大的微博

 

 


Time taken for tests:   32.690 seconds

Complete requests:      20000

Failed requests:        0

Write errors:           0

Non-2xx responses:      20000

Total transferred:      13520000 bytes

Total POSTed:           5340000

HTML transferred:       9300000 bytes

Requests per second:    611.80 [#/sec] (mean)

Time per request:       81.726 [ms] (mean)

Time per request:       1.635 [ms] (mean, across all concurrent requests)

Transfer rate:          403.88 [Kbytes/sec] received

                        159.52 kb/s sent

                        563.41 kb/s total

 

Connection Times (ms)

              min  mean[+/-sd] median   max

Connect:        0    0   0.9      0      19

Processing:    14   82   8.4     81     153

Waiting:        4   82   8.4     80     153

Total:         20   82   8.2     81     153

 

Percentage of the requests served within a certain time (ms)

  50%     81

  66%     84

  75%     86

  80%     88

  90%     93

  95%     96

  98%    100

  99%    103

 100%    153 (longest request)

 

 

测试结果 :

50 个并发 , 20000 次请求 ,  虚拟下 , 未做特殊优化

每次请求 redis 写操作 6 次 .

30+ 秒左右完成 .

 

平均每秒发布 700 条微博 , 4000 次 redis 写入 .

后台定时任务 , 回归冷数据入 mysql
Redis 配置文件

 daemonize yes   # redis 是否以后台进程运行

 Requirepass   密码  #  配置 redis 连接的密码

注 : 配置密码后 , 客户端连上服务器 , 需要先执行授权命令

# auth  密码

 ============================

$userId=$r->incr('globle:userId');  $r是redis对象

$r->set('user:userId:'.$userId'.':username',$username);

$r->set('user:userId:'.$userId'.':passwd',$passwd);

$r->set('user:username:'.$username.':userId',$userid);

$r->lpush('newuserlink',$userId);

$r->ltrim('newuserlink',0,49);   //最新的50个用户

$newlist=$r->sort('newuserlink',array('sort'=>'desc','get'=>'user:userId:*:username');   对链表排序，*代表newuserlink取出的数据

$r->sadd('following:userId'.$userId,$otherId);  关注与被关注

$r->sadd('follower:userId'.$otherId,$userId);   

cookie  防止被人篡改，可在服务器端设置一个随机数，setcookie中，服务器端在存一份，等在页面跳转的时候再进行判断，等用户推出的时候，再把他销毁

$r->hmset('post:postId'.$postId, array('userId'=>xxxx'content'=>xxxx,'time'=>'xxxxxx'));

数据存的时候可适当的添加冗余的字段，这样可以减少连表的查询，如 疯兔的user_purchase表




显示微博多长时间以前发布的函数： 当前的戳-生成时的戳   然后根据秒数来分成 天数   小时   分钟 秒的等级